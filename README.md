# Task 1 - Data Pipeline (ETL)

## ğŸ“Œ Internship
CODTECH Data Science Internship

## ğŸ“– Description
This project demonstrates the creation of a data preprocessing pipeline using Python. The pipeline handles missing values, feature scaling, and data splitting for machine learning models.

## ğŸš€ Objectives
- Build an ETL (Extract, Transform, Load) pipeline
- Handle missing data
- Normalize features using scaling
- Prepare dataset for ML model training

## ğŸ› ï¸ Tools & Libraries Used
- Python
- Pandas
- NumPy
- Scikit-learn

## ğŸ“‚ Dataset
A sample dataset was created manually to demonstrate preprocessing techniques such as handling missing values and feature scaling.

## âš™ï¸ Steps Performed

### 1. Data Loading
- Loaded dataset using Pandas

### 2. Data Cleaning
- Handled missing values using SimpleImputer

### 3. Feature Scaling
- Applied StandardScaler to normalize data

### 4. Pipeline Creation
- Combined preprocessing steps using Scikit-learn Pipeline

### 5. Train-Test Split
- Split data into training and testing sets

## ğŸ“Š Output
- Cleaned and processed dataset ready for machine learning models

## â–¶ï¸ How to Run

```bash
pip install -r requirements.txt
python data_pipeline.py
